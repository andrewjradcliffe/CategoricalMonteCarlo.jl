#
# Date created: 2022-06-21
# Author: aradclif
#
#
############################################################################################
# https://www.jstatsoft.org/article/view/v011i03
#### Marsaglia's Square Histogram (Method II in the above article)
# p ‚àà ‚Ñù·¥∫, ‚àë·µ¢p·µ¢ = 1, a = 1/N
# K ‚àà ‚Ñï·¥∫, K·µ¢ = i
# V ‚àà ‚Ñù‚Åø, V·µ¢ = i * a
# Generate: j = ‚åäN*U+1‚åã; if U < V[j], return j, else return K[j]
# Theoretically, just one U ~ Uniform(0,1) is sufficient. In practice, it is also faster as
#     U=rand(); j=floor(Int, N * U + 1)
# is far fewer instructions than
#     j=rand(1:N); U=rand()
#### Robin Hood
## Motivation
# The frequency of the `else` statement being required is proportional to the "over-area",
# i.e. the part of the final squared histogram that lies above the division points.
# Or, to quantify it: ‚àë·µ¢ (i * a) - V[i]
# The objective is to minimize the number of times the `else return K[j]` occurs
# by creating V such that each V[j] is as close to j/N as possible -- an NP-hard problem.
# Marsaglia's suggestion of the Robin Hood method is a good solution which is ùí™(NlogN).
## Thoughts
# The reduction in `else` statements leads to faster sampling -- ùí™(1) regardless --
# as it would certainly lead to a more predictable instruction pipeline due to minimizing
# the number of times the `else` branch is executed (or used, even if executed).
# Does it justify the ùí™(NlogN) construction cost for the alias tables? -- given
# that we could pay ùí™(N) instead to construct an inferior table (but no limit on how terrible).
#     - An analysis based on the objective function above would be informative;
#       can be verified with Monte Carlo: compute ùíª(ùê±) = ‚àë·µ¢ (i * a) - V[i]
#       using the V produced by each procedure.
#     - Number of samples to be drawn is an orthogonal decision variable;
#       one surmises that increasing number of samples favor better table.
## Algorithm
# repeat these two steps N - 1 times
#     1. find the smallest probability, p·µ¢, and the largest probability, p‚±º
#     2. set K[i] = j; V[i] = (i - 1) * a + p·µ¢; replace p‚±º with p‚±º - (a - p·µ¢)
## Numerical stability
# Replacing p‚±º is the only point at which stability is a real concern. There are a few
# options for the order of operations and parenthesis. Unsurprisingly, Marsaglia gives
# the most stable form: p‚±º = p‚±º - (a - p·µ¢)
# But it is worthwhile to show that this is the most stable form.
#     First, consider that it should be the case that p·µ¢ ‚â§ a, hence 0 ‚â§ (a - p·µ¢) ‚â§ 1/n.
#     (a - p·µ¢) may be a small number, but (a - p·µ¢) is always well-defined since it occurs
#     at eps(a)‚â°ulp(a).
# It is worth noting that the (a - p·µ¢) operation becomes unstable when p·µ¢ ‚â§ eps(a)/4, assuming
# the worst case, a=1. However, this has the opposite relationship to n: increasing n will
# result in a subtraction which takes place at smaller values, hence, the (floating)
# points are more densely packed (i.e. distance to nearest float is smaller).
# It is reassuring to note that eps(.5) = 2‚Åª‚Åµ¬≥, hence, even for a vector of length 2,
# the (a - p·µ¢) is stable for p·µ¢ > 2‚Åª‚Åµ‚Åµ.
#     The subsequent subtraction, i.e. p‚±º - (a - p·µ¢), will occur at eps(p‚±º)‚â°ulp(p‚±º). Thus,
#     the operation will be unstable when p‚±º - c * ulp(p‚±º), c ‚â§ 1/4 (for p‚±º = 1, the worst case).
# That is, unstable when: (a - p·µ¢) ‚â§ eps(p‚±º)/4
# If p·µ¢ ‚âà 0, (a - p·µ¢) ‚âà 1/n ‚üπ 1/n ‚â§ eps(p‚±º)/4 is unstable
# As p‚±º is at most 1, the worst case will be eps(p‚±º)/4 = 2‚Åª‚Åµ‚Å¥, i.e. 1/n ‚â§ 2‚Åª‚Åµ‚Å¥.
# ‚à¥ in the worse case, instability begins at n ‚â• 2‚Åµ‚Å¥ if p·µ¢ ‚âà 0.
# ‚à¥ in general, expect instability if (a - p·µ¢) ‚â§ 2‚Åª‚Åµ‚Å¥.
# The above assumed Float64 with 53 bits of precision; the general form in terms of precision
# replaces 2‚Åª‚Åµ‚Å¥ ‚Üí 2‚Åª·µñ‚Åª¬π.
# These are very permissive bounds; one is likely to run into other issues well before
# the algorithm becomes numerically unstable.
## Numerical stability, revisit
# Oddly, Marsaglia's implementation in TplusSQ.c uses p‚±º + p·µ¢ - a, which has slightly
# worse numerical stability. (p‚±º + p·µ¢) becomes unstable when p·µ¢ ‚â§ eps(p‚±º)/2, which
# corresponds to 2‚Åª·µñ at p‚±º = 1.
# It is possible to find cases where both suffer roundoff, which is ‚â§ 2‚Åª·µñ‚Å∫¬π for p‚±º + p·µ¢ - a
# and ‚â§ 2‚Åª·µñ for p‚±º - (a - p·µ¢).
# Provided that one is working with Float64, it most likely does not matter.
# However, if p is provided as Float32, it may be preferable to forcibly promote to Float64
# just to ensure stability; naturally, Float16 is largely unsuitable and needs promotion.
# ##
# # Comparison of stability
# # f1 is unstable at n = 10, q‚±º = .999999999999
# # However, f2 and f3 are unstable at n = 10, q‚±º = 5
# f1(q‚±º, q·µ¢, a) = q‚±º - (a - q·µ¢)
# f2(q‚±º, q·µ¢, a) = q‚±º + q·µ¢ - a
# ff2(q‚±º, q·µ¢, a) = @fastmath q‚±º + q·µ¢ - a
# f3(q‚±º, q·µ¢, a) = (q‚±º + q·µ¢) - a
# n = 10
# a = 1 / n
# q‚±º = .999999999999
# q·µ¢ = (1 - q‚±º) / n
# f1(q‚±º, q·µ¢, a)
# f2(q‚±º, q·µ¢, a)
# ff2(q‚±º, q·µ¢, a)
# f3(q‚±º, q·µ¢, a)
# f1(big(q‚±º), big(q·µ¢), big(a))
# f2(big(q‚±º), big(q·µ¢), big(a))
# f3(big(q‚±º), big(q·µ¢), big(a))

function marsaglia(p::Vector{T}) where {T<:AbstractFloat}
    n = length(p)
    K = Vector{Int}(undef, n)
    V = Vector{promote_type(T, Float64)}(undef, n)
    q = similar(p, promote_type(T, Float64))
    a = inv(n)
    # initialize
    @inbounds for i ‚àà eachindex(K, V, p, q)
        K[i] = i
        V[i] = i * a
        q[i] = p[i]
    end
    for _ = 1:n-1
        q·µ¢, i = findmin(q)
        q‚±º, j = findmax(q)
        K[i] = j
        V[i] = (i - 1) * a + q·µ¢
        q[j] = q‚±º - (a - q·µ¢)
        q[i] = a
    end
    K, V
end

function vmarsaglia(p::Vector{T}) where {T<:AbstractFloat}
    n = length(p)
    K = Vector{Int}(undef, n)
    V = Vector{promote_type(T, Float64)}(undef, n)
    a = inv(n)
    q = similar(p, promote_type(T, Float64))
    # initialize
    @turbo for i ‚àà eachindex(K, V, p, q)
        K[i] = i
        V[i] = i * a
        q[i] = p[i]
    end
    for _ = 1:n-1
        q·µ¢, i = vfindmin(q)
        q‚±º, j = vfindmax(q)
        K[i] = j
        V[i] = (i - 1) * a + q·µ¢
        q[j] = q‚±º - (a - q·µ¢)
        q[i] = a
    end
    K, V
end

# p = [0.2, 0.3, 0.1, 0.4]

# p = [.21, .18, .26, .17, .18]

# p = [2/15, 7/15, 6/15]

function marsaglia_generate(K::Vector{Int}, V::Vector{T}) where {T<:AbstractFloat}
    n = length(K)
    u = rand()
    j = trunc(Int, muladd(u, n, 1))
    u < V[j] ? j : K[j]
end

function marsaglia_generate!(A::AbstractArray, K::Vector{Int}, V::Vector{T}) where {T<:AbstractFloat}
    length(K) == length(V) || throw(ArgumentError("K and V must be of same size"))
    n = length(K)
    @inbounds for i ‚àà eachindex(A) # safe to also use @fastmath, @simd
        u = rand()
        j = trunc(Int, muladd(u, n, 1)) # muladd is faster than u * n + 1 by ‚âà5-6%
        A[i] = u < V[j] ? j : K[j]
    end
    A
end
function marsaglia_generate!(A::AbstractArray, u::AbstractArray{Float64}, K::Vector{Int}, V::Vector{T}) where {T<:AbstractFloat}
    length(K) == length(V) || throw(ArgumentError("K and V must be of same size"))
    n = length(K)
    rand!(u)
    @inbounds for i ‚àà eachindex(A, u) # safe to also use @fastmath, @simd
        j = trunc(Int, muladd(u[i], n, 1)) # muladd is faster than u * n + 1 by ‚âà5-6%
        A[i] = u[i] < V[j] ? j : K[j]
    end
    A
end

function marsaglia_generate(K::Vector{Int}, V::Vector{T}, dims::Vararg{Int, N}) where {T<:AbstractFloat} where {N}
    marsaglia_generate!(Array{Int}(undef, dims), K, V)
end

function marsaglia!(K::Vector{Int}, V::Vector{T}, q::Vector{T}, p::Vector{T}) where {T<:AbstractFloat}
    (length(K) == length(V) == length(q) == length(p)) || throw(ArgumentError("all inputs must be of same size"))
    n = length(p)
    a = inv(n)
    @inbounds for i ‚àà eachindex(K, V, p, q)
        K[i] = i
        V[i] = i * a
        q[i] = p[i]
    end
    for _ = 1:n-1
        q·µ¢, i = findmin(q)
        q‚±º, j = findmax(q)
        K[i] = j
        V[i] = (i - 1) * a + q·µ¢
        q[j] = q‚±º - (a - q·µ¢)
        q[i] = a
    end
    K, V
end

function vmarsaglia!(K::Vector{Int}, V::Vector{T}, q::Vector{T}, p::Vector{T}) where {T<:AbstractFloat}
    (length(K) == length(V) == length(q) == length(p)) || throw(ArgumentError("all inputs must be of same size"))
    n = length(p)
    a = inv(n)
    @inbounds for i ‚àà eachindex(K, V, p, q)
        K[i] = i
        V[i] = i * a
        q[i] = p[i]
    end
    for _ = 1:n-1
        q·µ¢, i = vfindmin(q)
        q‚±º, j = vfindmax(q)
        K[i] = j
        V[i] = (i - 1) * a + q·µ¢
        q[j] = q‚±º - (a - q·µ¢)
        q[i] = a
    end
    K, V
end

# faster, but not necessarily the method to use due to LoopVectorization and Base.Threads
# alas, it is ‚âà5x faster
function vmarsaglia_generate!(A::AbstractArray, K::Vector{Int}, V::Vector{T}) where {T<:AbstractFloat}
    length(K) == length(V) || throw(ArgumentError("K and V must be of same size"))
    n = length(K)
    u = rand(length(A))
    @turbo for i ‚àà eachindex(A, u)
        j = trunc(Int, muladd(u[i], n, 1))
        A[i] = ifelse(u[i] < V[j], j, K[j])
    end
    A
end
function vmarsaglia_generate!(A::AbstractArray, u::AbstractArray{Float64}, K::Vector{Int}, V::Vector{T}) where {T<:AbstractFloat}
    length(K) == length(V) || throw(ArgumentError("K and V must be of same size"))
    n = length(K)
    rand!(u)
    @turbo for i ‚àà eachindex(A, u)
        j = trunc(Int, muladd(u[i], n, 1))
        A[i] = ifelse(u[i] < V[j], j, K[j])
    end
    A
end

function vmarsaglia_generate(K::Vector{Int}, V::Vector{T}, dims::Vararg{Int, N}) where {T<:AbstractFloat} where {N}
    vmarsaglia_generate!(Array{Int}(undef, dims), K, V)
end

################
# convenience utils
@inline _marsaglia_init(T::Type{<:AbstractFloat}, n::Int) = Vector{Int}(undef, n), Vector{T}(undef, n), Vector{T}(undef, n)
@inline _marsaglia_init(T::Type{<:AbstractFloat}) = _marsaglia_init(T, 0)
@inline _marsaglia_init() = _marsaglia_init(Float64)

@inline _genstorage_init(T::Type{<:AbstractFloat}, n::Int) = Vector{Int}(undef, n), Vector{T}(undef, n)

################
# experimental

mutable struct MarsagliaSquareHistogram{Ti<:Integer, Tv<:AbstractFloat}
    K::Vector{Ti}
    V::Vector{Tv}
    n::Int
end

# MarsagliaSquareHistogram{Ti, Tv}(K, V, n) where {Ti<:Integer, Tv<:AbstractFloat} =
#     MarsagliaSquareHistogram(convert(Vector{Ti}, K), convert(Vector{Tv}, V), n)

MarsagliaSquareHistogram(K, V) = MarsagliaSquareHistogram(K, V, length(K))

MarsagliaSquareHistogram((K, V), n) = MarsagliaSquareHistogram(K, V, n)
MarsagliaSquareHistogram(p) = MarsagliaSquareHistogram(marsaglia(p), length(p))

vmarsaglia_generate!(C, t::MarsagliaSquareHistogram) = ((; K, V, n) = t; vmarsaglia_generate!(C, K, V))
vmarsaglia_generate!(C, U, t::MarsagliaSquareHistogram) = ((; K, V, n) = t; vmarsaglia_generate!(C, U, K, V))
vmarsaglia_generate(t::MarsagliaSquareHistogram, dims::Vararg{Int, N}) where {N} =
    vmarsaglia_generate!(Array{Int}(undef, dims), t)


################
# Equal probability case admits an optimized form:
# U ~ Uniform(0,1)
# j = ‚åänU + 1‚åã; return j
function vfill!(A::AbstractArray, v::Real)
    @turbo for i ‚àà eachindex(A)
        A[i] = v
    end
    A
end

function vmarsaglia_generate!(A::AbstractArray, u::AbstractArray{Float64}, n::Int)
    n > 0 || throw(ArgumentError("n must be > 0"))
    n == 1 && return vfill!(A, 1)
    rand!(u)
    @turbo for i ‚àà eachindex(A, u)
        A[i] = trunc(Int, muladd(u[i], n, 1))
    end
    A
end

vmarsaglia_generate!(A::AbstractArray, n::Int) = vmarsaglia_generate!(A, similar(A, Float64), n)

